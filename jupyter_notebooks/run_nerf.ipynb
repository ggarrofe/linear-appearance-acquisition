{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Kzgp6r3nmXY7","outputId":"5a0888e4-844b-4195-c740-30c9353e5336","executionInfo":{"status":"ok","timestamp":1658951810092,"user_tz":-60,"elapsed":80459,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting configargparse\n","  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n","Installing collected packages: configargparse\n","Successfully installed configargparse-1.5.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.8.0-py2.py3-none-any.whl (153 kB)\n","\u001b[K     |████████████████████████████████| 153 kB 86.7 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 79.7 MB/s \n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=2762ed7a054e178f19659f53a21e04aff468502cfa1005fdf24223badb5c6b19\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.8.0 setproctitle-1.3.0 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.21\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting open3d\n","  Downloading open3d-0.15.2-cp37-cp37m-manylinux_2_27_x86_64.whl (408.6 MB)\n","\u001b[K     |████████████████████████████████| 408.6 MB 28 kB/s \n","\u001b[?25hCollecting jupyterlab==3.*,>=3.0.0\n","  Downloading jupyterlab-3.4.4-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from open3d) (4.64.0)\n","Collecting pyyaml>=5.4.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 78.5 MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.36.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (0.37.1)\n","Collecting pyquaternion\n","  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n","Collecting pillow>=8.2.0\n","  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 51.6 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (57.4.0)\n","Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (7.7.1)\n","Collecting pygments>=2.7.4\n","  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 56.9 MB/s \n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: numpy>1.15 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.0.2)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.7/dist-packages (from open3d) (3.2.2)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.3.5)\n","Collecting jupyter-packaging~=0.10\n","  Downloading jupyter_packaging-0.12.2-py3-none-any.whl (15 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (21.3)\n","Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (2.11.3)\n","Collecting tornado>=6.1.0\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[K     |████████████████████████████████| 423 kB 87.6 MB/s \n","\u001b[?25hCollecting nbclassic\n","  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n","\u001b[K     |████████████████████████████████| 9.7 MB 50.1 MB/s \n","\u001b[?25hCollecting jupyterlab-server~=2.10\n","  Downloading jupyterlab_server-2.15.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (5.3.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (4.11.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (5.5.0)\n","Collecting jupyter-server~=1.16\n","  Downloading jupyter_server-1.18.1-py3-none-any.whl (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 93.6 MB/s \n","\u001b[?25hRequirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (3.6.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (5.1.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (1.1.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (4.10.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (5.3.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.7.5)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.1->jupyterlab==3.*,>=3.0.0->open3d) (2.0.1)\n","Collecting setuptools>=40.8.0\n","  Downloading setuptools-63.2.0-py3-none-any.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 65.1 MB/s \n","\u001b[?25hCollecting deprecation\n","  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Collecting tomlkit\n","  Downloading tomlkit-0.11.1-py3-none-any.whl (34 kB)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.8.0)\n","Collecting websocket-client\n","  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n","\u001b[?25hRequirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.13.3)\n","Collecting nbconvert>=6.4.4\n","  Downloading nbconvert-6.5.0-py3-none-any.whl (561 kB)\n","\u001b[K     |████████████████████████████████| 561 kB 79.5 MB/s \n","\u001b[?25hCollecting jupyter-client\n","  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 80.1 MB/s \n","\u001b[?25hRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (21.3.0)\n","Collecting anyio<4,>=3.1.0\n","  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 9.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (23.2.0)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.14.1)\n","Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (5.4.0)\n","Collecting sniffio>=1.1\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (4.1.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (2.10)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (0.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (2.8.2)\n","Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (1.5.5)\n","Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (2.10.3)\n","Collecting json5\n","  Downloading json5-0.9.8.tar.gz (22 kB)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (4.12.0)\n","Collecting jinja2>=2.1\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 87.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (2.23.0)\n","Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (4.3.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (3.8.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (21.4.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (0.18.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.6.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (4.6.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.8.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.2.2)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.1.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (5.0.1)\n","Collecting traitlets>=4.3.1\n","  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 89.4 MB/s \n","\u001b[?25hRequirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (2.16.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->open3d) (2022.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.*,>=3.0.0->open3d) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (1.7.3)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (21.2.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (2.21)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.5.1)\n","Collecting notebook-shim>=0.1.0\n","  Downloading notebook_shim-0.1.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (2022.6.15)\n","Building wheels for collected packages: json5\n","  Building wheel for json5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for json5: filename=json5-0.9.8-py2.py3-none-any.whl size=18604 sha256=9b590815c9c9a6563b073cb9be31d70536e942090c5ae708345a5a68614ce62d\n","  Stored in directory: /root/.cache/pip/wheels/ac/9b/de/6e4fd8f159d3dfa42c42ceddf2184fda29ea7fb1e8f5f8371c\n","Successfully built json5\n","Installing collected packages: traitlets, tornado, jupyter-client, sniffio, setuptools, pygments, jinja2, websocket-client, nbconvert, anyio, jupyter-server, notebook-shim, json5, tomlkit, nbclassic, jupyterlab-server, deprecation, pyyaml, pyquaternion, pillow, jupyterlab, jupyter-packaging, addict, open3d\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 5.1.1\n","    Uninstalling traitlets-5.1.1:\n","      Successfully uninstalled traitlets-5.1.1\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter-client 5.3.5\n","    Uninstalling jupyter-client-5.3.5:\n","      Successfully uninstalled jupyter-client-5.3.5\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.6.1\n","    Uninstalling Pygments-2.6.1:\n","      Successfully uninstalled Pygments-2.6.1\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: nbconvert\n","    Found existing installation: nbconvert 5.6.1\n","    Uninstalling nbconvert-5.6.1:\n","      Successfully uninstalled nbconvert-5.6.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n","flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed addict-2.4.0 anyio-3.6.1 deprecation-2.1.0 jinja2-3.1.2 json5-0.9.8 jupyter-client-7.3.4 jupyter-packaging-0.12.2 jupyter-server-1.18.1 jupyterlab-3.4.4 jupyterlab-server-2.15.0 nbclassic-0.4.3 nbconvert-6.5.0 notebook-shim-0.1.0 open3d-0.15.2 pillow-9.2.0 pygments-2.12.0 pyquaternion-0.9.9 pyyaml-6.0 setuptools-63.2.0 sniffio-1.2.0 tomlkit-0.11.1 tornado-6.2 traitlets-5.3.0 websocket-client-1.3.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","pkg_resources","pygments","tornado"]}}},"metadata":{}}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","! pip install configargparse\n","! pip install wandb\n","! pip install open3d"]},{"cell_type":"markdown","metadata":{"id":"PBdK0o3HTxzd"},"source":["## Run NeRF\n","WandB apikey: 209f6ac4375563c3d09904b96206a2f5f1d75c24\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nR9SzdLnPyj","outputId":"819f3166-73a0-4f75-a046-ad5f9c9390df"},"outputs":[{"name":"stdout","output_type":"stream","text":["usage: main.py [-h] [-c CONFIG] [--mesh MESH] [--dataset_path DATASET_PATH]\n","               [--out_path OUT_PATH]\n","               [--dataset_type {synthetic,llff,tiny,meshroom,colmap}]\n","               [--factor FACTOR] [--batch_size BATCH_SIZE] [--shuffle SHUFFLE]\n","               [--N_samples N_SAMPLES] [--D_c D_C] [--W_c W_C] [--N_f N_F]\n","               [--lrate LRATE] [--lrate_decay LRATE_DECAY] [--N_iters N_ITERS]\n","               [--near NEAR] [--far FAR] [--raw_noise_std RAW_NOISE_STD]\n","               [--dataset_to_gpu] [--colab] [--colab_path COLAB_PATH] [--test]\n","main.py: error: argument --batch_size: invalid int value: '1024*8'\n"]}],"source":["! python3 drive/Othercomputers/MacBookPro/NeRF/main.py -c drive/Othercomputers/MacBookPro/NeRF/configs/lego_llff_colab.conf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKm4sJvS4xrs"},"outputs":[],"source":["! python3 drive/Othercomputers/MacBookPro/nerf-pytorch/run_nerf.py --config drive/Othercomputers/MacBookPro/nerf-pytorch/configs/orchids.txt"]},{"cell_type":"markdown","metadata":{"id":"uw3rtMXaUCnm"},"source":["## Run Ray tracing a mesh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TOT06fhfvRf"},"outputs":[],"source":["! python3 drive/Othercomputers/MacBookPro/Ray-tracing_mesh/ray_tracing_mesh.py -c drive/Othercomputers/MacBookPro/Ray-tracing_mesh/configs/lego_llff.conf"]},{"cell_type":"markdown","metadata":{"id":"a5bqQ-56fIsL"},"source":["## Surface rendering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88FUguwEgjeD","outputId":"17846d16-9527-475a-aea3-ef3f9fbc3be2"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.11.0+cu113\n","Name: torch\n","Version: 1.11.0+cu113\n","Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n","Home-page: https://pytorch.org/\n","Author: PyTorch Team\n","Author-email: packages@pytorch.org\n","License: BSD-3\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: typing-extensions\n","Required-by: torchvision, torchtext, torchaudio, fastai\n"]}],"source":["import torch\n","print(torch.__version__)\n","! pip3 show torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVdYBt1n2xEd","outputId":"17b12885-7f2c-429f-a567-a5af6bf2a33a","executionInfo":{"status":"ok","timestamp":1657649733278,"user_tz":-60,"elapsed":393,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file 'drive/Othercomputers/MacBookPro/NeRF/surface_rendering.py': [Errno 2] No such file or directory\n"]}],"source":["! python3 drive/Othercomputers/MacBookPro/Rendering/surface_rendering.py -c drive/Othercomputers/MacBookPro/Rendering/configs/surfrend_colab.conf"]},{"cell_type":"markdown","source":["## Radiance Linear Mapping"],"metadata":{"id":"3dcUI9ProFcD"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"TroGNWt02zPr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"38c1c9fb-a5cc-44f5-e051-197d3eaa7b60","executionInfo":{"status":"ok","timestamp":1658843917533,"user_tz":-60,"elapsed":237239,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["drive/Othercomputers/MacBookPro/utils/utils.py:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert(old_arr.shape == new_arr.shape, \"The 2 arrays have different shape, cannot find the differences.\")\n","Using cuda\n","dataset to:  cpu\n","['train', 'val']\n","tcmalloc: large alloc 1612800000 bytes == 0x8a20000 @  0x7f5de69aa001 0x7f5d762981af 0x7f5d762eec23 0x7f5d762efa87 0x7f5d76391823 0x5936cc 0x548c51 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f5de65a5c87 0x5b621a\n","Loading train - 100 poses and images (800x800)...\n","\tChanged 1150 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (0, 0, 0) to (99, 2, 3)\n","Loading val - 5 poses and images (800x800)...\n","\tChanged 59 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (100, 0, 0) to (104, 2, 3)\n","Focal length: 785.0441767523804\n","Generating rays: 100% 105/105 [00:19<00:00,  5.43pose/s]\n","tcmalloc: large alloc 3225600000 bytes == 0x129062000 @  0x7f5de698ab6b 0x7f5de69aa379 0x7f5d76f80d57 0x7f5d76f6ebc3 0x7f5da0e6439f 0x7f5da0e64d10 0x7f5da0e64d64 0x7f5da0e64eaf 0x7f5da1bea53b 0x7f5da1c4da52 0x7f5da138f047 0x7f5da1bf35ae 0x7f5da1bf3633 0x7f5da1704725 0x7f5da13a1741 0x7f5da1d37983 0x7f5da180b90c 0x7f5da2d23b1d 0x7f5da2d24026 0x7f5da185d1d2 0x7f5dc8c28343 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96\n","Creating datasets...\n","tcmalloc: large alloc 3072000000 bytes == 0x68c36000 @  0x7f5de698ab6b 0x7f5de69aa379 0x7f5d76f80d57 0x7f5d76f6ebc3 0x7f5da0e6439f 0x7f5da0e64d10 0x7f5da0e64d64 0x7f5da1375fff 0x7f5da1be689b 0x7f5da1932223 0x7f5da1bc19bf 0x7f5da196fbf7 0x7f5da0ea832c 0x7f5da0ea9dcf 0x7f5da0eab783 0x7f5da133e0a6 0x7f5da134acd9 0x7f5da1be6d10 0x7f5da17f82bc 0x7f5da2cf887d 0x7f5da2cf8f63 0x7f5da18480fb 0x7f5dc8daf8e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","tcmalloc: large alloc 1536000000 bytes == 0x7f5c8fcea000 @  0x7f5de698ab6b 0x7f5de69aa379 0x7f5d76f80d57 0x7f5d76f6ebc3 0x7f5da0e6439f 0x7f5da0e64d10 0x7f5da0e64d64 0x7f5da1375fff 0x7f5da1be689b 0x7f5da1932223 0x7f5da1bc19bf 0x7f5da196fbf7 0x7f5da0ea832c 0x7f5da0ea9dcf 0x7f5da0eab783 0x7f5da133e0a6 0x7f5da134acd9 0x7f5da1be6d10 0x7f5da17f82bc 0x7f5da2cf887d 0x7f5da2cf8f63 0x7f5da18480fb 0x7f5dc8daf8e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","\tComputing view dirs for train...\n","tcmalloc: large alloc 4608000000 bytes == 0x7f5ae48fa000 @  0x7f5de698ab6b 0x7f5de69aa379 0x7f5d76f80d57 0x7f5d76f6ebc3 0x7f5da0e6439f 0x7f5da0e64d10 0x7f5da0e64d64 0x7f5da0e64eaf 0x7f5da1bea53b 0x7f5da1c4da52 0x7f5da138f047 0x7f5da1bf35ae 0x7f5da1bf3633 0x7f5da16c866c 0x7f5da2c3c380 0x7f5da2c3cb36 0x7f5da1704725 0x7f5dc8c4aa62 0x593835 0x548c51 0x5127f1 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576\n","\tCreating train dataset with rays (torch.Size([64000000, 9])) and images (torch.Size([64000000, 3])) - shuffle True\n","\tComputing view dirs for val...\n","\tCreating val dataset with rays (torch.Size([3200000, 9])) and images (torch.Size([3200000, 3])) - shuffle True\n","Datasets created successfully\n","\n","Reading PLY file: drive/Othercomputers/MacBookPro/hotdog/hot-dogs2.ply[========================================] 100%\n","tcmalloc: large alloc 4608000000 bytes == 0x8a20000 @  0x7f5de698ab6b 0x7f5de69aa379 0x7f5d76f80d57 0x7f5d76f6ebc3 0x7f5da0e6439f 0x7f5da0e64d10 0x7f5da0e64d64 0x7f5da0e64eaf 0x7f5da1bea53b 0x7f5da1c4da52 0x7f5da138f047 0x7f5da1bf35ae 0x7f5da1bf3633 0x7f5da16c866c 0x7f5da2c3c380 0x7f5da2c3cb36 0x7f5da1704725 0x7f5dc8c4aa62 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x604173\n","tcmalloc: large alloc 2304000000 bytes == 0x11b4a8000 @  0x7f5de698ab6b 0x7f5de69aa379 0x7f5d76f80d57 0x7f5d76f6ebc3 0x7f5da0e6356f 0x7f5da0e637ba 0x7f5da0e6381f 0x7f5da1376059 0x7f5da1be69c0 0x7f5da193243e 0x7f5da1bbfc7e 0x7f5da19722c2 0x7f5da1370501 0x7f5da1d37e2b 0x7f5da16bd1cf 0x7f5da1bc1dfc 0x7f5da16bd1cf 0x7f5da2c3355b 0x7f5da2c339be 0x7f5da1735164 0x7f5da136545b 0x7f5da1e35350 0x7f5da1865bdf 0x7f5dc8b1085f 0x7f5dc8b108fc 0x7f5dc8b11dc8 0x59b1b0 0x515655 0x549576 0x593fce 0x548ae9\n","Running kmeans on cuda: 7it [01:37, 13.88s/it, center_shift=0.091397, num_clusters=599, tol=0.100000]\n","Computing linear mappings: 100% 598/600 [01:06<00:00,  8.86linear mapping/s]\n","Filtering 34837302 points:   0% 0/35 [00:00<?, ?batch/s]\u001b[A\n","Filtering 34837302 points:   6% 2/35 [00:00<00:02, 16.18batch/s]\u001b[A\n","Filtering 34837302 points:  11% 4/35 [00:00<00:02, 11.54batch/s]\u001b[A\n","Filtering 34837302 points:  17% 6/35 [00:00<00:03,  9.58batch/s]\u001b[A\n","Filtering 34837302 points:  23% 8/35 [00:00<00:03,  8.22batch/s]\u001b[A\n","Filtering 34837302 points:  26% 9/35 [00:01<00:03,  7.47batch/s]\u001b[A\n","Filtering 34837302 points:  29% 10/35 [00:01<00:03,  6.78batch/s]\u001b[A\n","Filtering 34837302 points:  31% 11/35 [00:01<00:03,  6.15batch/s]\u001b[A\n","Filtering 34837302 points:  34% 12/35 [00:01<00:04,  5.66batch/s]\u001b[A\n","Filtering 34837302 points:  37% 13/35 [00:01<00:04,  5.20batch/s]\u001b[A\n","Filtering 34837302 points:  40% 14/35 [00:02<00:04,  4.88batch/s]\u001b[A\n","Filtering 34837302 points:  43% 15/35 [00:02<00:04,  4.58batch/s]\u001b[A\n","Filtering 34837302 points:  46% 16/35 [00:02<00:04,  4.28batch/s]\u001b[A\n","Filtering 34837302 points:  49% 17/35 [00:02<00:04,  4.00batch/s]\u001b[A\n","Filtering 34837302 points:  51% 18/35 [00:03<00:04,  3.79batch/s]\u001b[A\n","Filtering 34837302 points:  54% 19/35 [00:03<00:04,  3.59batch/s]\u001b[A\n","Filtering 34837302 points:  57% 20/35 [00:03<00:04,  3.41batch/s]\u001b[A\n","Filtering 34837302 points:  60% 21/35 [00:04<00:04,  3.26batch/s]\u001b[A\n","Filtering 34837302 points:  63% 22/35 [00:04<00:04,  3.11batch/s]\u001b[A\n","Filtering 34837302 points:  66% 23/35 [00:04<00:04,  2.97batch/s]\u001b[A\n","Filtering 34837302 points:  69% 24/35 [00:05<00:03,  2.84batch/s]\u001b[A\n","Filtering 34837302 points:  71% 25/35 [00:05<00:03,  2.75batch/s]\u001b[A\n","Filtering 34837302 points:  74% 26/35 [00:06<00:03,  2.64batch/s]\u001b[A\n","Filtering 34837302 points:  77% 27/35 [00:06<00:03,  2.55batch/s]\u001b[A\n","Filtering 34837302 points:  80% 28/35 [00:07<00:02,  2.47batch/s]\u001b[A\n","Filtering 34837302 points:  83% 29/35 [00:07<00:02,  2.39batch/s]\u001b[A\n","Filtering 34837302 points:  86% 30/35 [00:07<00:02,  2.32batch/s]\u001b[A\n","Filtering 34837302 points:  89% 31/35 [00:08<00:01,  2.24batch/s]\u001b[A\n","Filtering 34837302 points:  91% 32/35 [00:08<00:01,  2.16batch/s]\u001b[A\n","Filtering 34837302 points:  94% 33/35 [00:09<00:00,  2.10batch/s]\u001b[A\n","Filtering 34837302 points:  97% 34/35 [00:09<00:00,  2.03batch/s]\u001b[A\n","Filtering 34837302 points: 100% 35/35 [00:10<00:00,  1.98batch/s]\u001b[A\n","                                                                 \u001b[AFiltered to 34837302\n","Computing linear mappings: 100% 599/600 [01:17<00:00,  7.77linear mapping/s]\n","Traceback (most recent call last):\n","  File \"drive/Othercomputers/MacBookPro/Rendering/radiance_mapping.py\", line 112, in <module>\n","    linear_mappings[cluster_id] = compute_inv(xnv, target_rgb, cluster_id, cluster_ids, embed_fn=embed_fn)\n","  File \"drive/Othercomputers/MacBookPro/Rendering/radiance_mapping.py\", line 53, in compute_inv\n","    xnv_enc_inv = torch.linalg.pinv(embed_fn(xnv))\n","  File \"drive/Othercomputers/MacBookPro/utils/embedder.py\", line 41, in embed\n","    def embed(x, eo=embedder_obj): return eo.embed(x)\n","  File \"drive/Othercomputers/MacBookPro/utils/embedder.py\", line 31, in embed\n","    return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n","  File \"drive/Othercomputers/MacBookPro/utils/embedder.py\", line 31, in <listcomp>\n","    return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n","  File \"drive/Othercomputers/MacBookPro/utils/embedder.py\", line 24, in <lambda>\n","    embed_fns.append(lambda x, fn=fn, freq=f: fn(x * freq))\n","RuntimeError: CUDA out of memory. Tried to allocate 1.17 GiB (GPU 0; 14.76 GiB total capacity; 11.73 GiB already allocated; 323.75 MiB free; 13.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"]}],"source":["! python3 drive/Othercomputers/MacBookPro/Rendering/radiance_mapping.py -c drive/Othercomputers/MacBookPro/Rendering/configs/radiancemap_colab.conf"]},{"cell_type":"markdown","source":["# Residual Reflectance"],"metadata":{"id":"NNAwcSy0Bg3a"}},{"cell_type":"code","source":["! python3 drive/Othercomputers/MacBookPro/Rendering/residual_reflectance.py -c drive/Othercomputers/MacBookPro/Rendering/configs/resref_colab.conf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NP64cGoHtdOl","outputId":"a28bbe32-7192-4739-fa96-111b1ed2d5c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda\n","dataset to:  cpu\n","['train', 'val']\n","tcmalloc: large alloc 1612800000 bytes == 0x8a3e000 @  0x7fcb49698001 0x7fcad8f861af 0x7fcad8fdcc23 0x7fcad8fdda87 0x7fcad907f823 0x5936cc 0x548c51 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fcb49293c87 0x5b621a\n","Loading train - 100 poses and images (800x800)...\n","\tChanged 1150 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (0, 0, 0) to (99, 2, 3)\n","Loading val - 5 poses and images (800x800)...\n","\tChanged 59 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (100, 0, 0) to (104, 2, 3)\n","Focal length: 785.0441767523804\n","Generating rays: 100% 105/105 [00:18<00:00,  5.59pose/s]\n","tcmalloc: large alloc 3225600000 bytes == 0x129092000 @  0x7fcb49678b6b 0x7fcb49698379 0x7fcad9c6ed57 0x7fcad9c5cbc3 0x7fcb03b5239f 0x7fcb03b52d10 0x7fcb03b52d64 0x7fcb03b52eaf 0x7fcb048d853b 0x7fcb0493ba52 0x7fcb0407d047 0x7fcb048e15ae 0x7fcb048e1633 0x7fcb043f2725 0x7fcb0408f741 0x7fcb04a25983 0x7fcb044f990c 0x7fcb05a11b1d 0x7fcb05a12026 0x7fcb0454b1d2 0x7fcb2b916343 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96\n","Creating datasets...\n","tcmalloc: large alloc 3072000000 bytes == 0x68c66000 @  0x7fcb49678b6b 0x7fcb49698379 0x7fcad9c6ed57 0x7fcad9c5cbc3 0x7fcb03b5239f 0x7fcb03b52d10 0x7fcb03b52d64 0x7fcb04063fff 0x7fcb048d489b 0x7fcb04620223 0x7fcb048af9bf 0x7fcb0465dbf7 0x7fcb03b9632c 0x7fcb03b97dcf 0x7fcb03b99783 0x7fcb0402c0a6 0x7fcb04038cd9 0x7fcb048d4d10 0x7fcb044e62bc 0x7fcb059e687d 0x7fcb059e6f63 0x7fcb045360fb 0x7fcb2ba9d8e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","tcmalloc: large alloc 1536000000 bytes == 0x7fc9f2a0e000 @  0x7fcb49678b6b 0x7fcb49698379 0x7fcad9c6ed57 0x7fcad9c5cbc3 0x7fcb03b5239f 0x7fcb03b52d10 0x7fcb03b52d64 0x7fcb04063fff 0x7fcb048d489b 0x7fcb04620223 0x7fcb048af9bf 0x7fcb0465dbf7 0x7fcb03b9632c 0x7fcb03b97dcf 0x7fcb03b99783 0x7fcb0402c0a6 0x7fcb04038cd9 0x7fcb048d4d10 0x7fcb044e62bc 0x7fcb059e687d 0x7fcb059e6f63 0x7fcb045360fb 0x7fcb2ba9d8e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","\tComputing view dirs for train...\n","tcmalloc: large alloc 4608000000 bytes == 0x7fc84761e000 @  0x7fcb49678b6b 0x7fcb49698379 0x7fcad9c6ed57 0x7fcad9c5cbc3 0x7fcb03b5239f 0x7fcb03b52d10 0x7fcb03b52d64 0x7fcb03b52eaf 0x7fcb048d853b 0x7fcb0493ba52 0x7fcb0407d047 0x7fcb048e15ae 0x7fcb048e1633 0x7fcb043b666c 0x7fcb0592a380 0x7fcb0592ab36 0x7fcb043f2725 0x7fcb2b938a62 0x593835 0x548c51 0x5127f1 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576\n","\tCreating train dataset with rays (torch.Size([64000000, 9])) and images (torch.Size([64000000, 3])) - shuffle True\n","\tComputing view dirs for val...\n","\tCreating val dataset with rays (torch.Size([3200000, 9])) and images (torch.Size([3200000, 3])) - shuffle True\n","Datasets created successfully\n","\n","Reading PLY file: drive/Othercomputers/MacBookPro/hotdog/hot-dogs2.ply[========================================] 100%\n","tcmalloc: large alloc 4608000000 bytes == 0x8a3e000 @  0x7fcb49678b6b 0x7fcb49698379 0x7fcad9c6ed57 0x7fcad9c5cbc3 0x7fcb03b5239f 0x7fcb03b52d10 0x7fcb03b52d64 0x7fcb03b52eaf 0x7fcb048d853b 0x7fcb0493ba52 0x7fcb0407d047 0x7fcb048e15ae 0x7fcb048e1633 0x7fcb043b666c 0x7fcb0592a380 0x7fcb0592ab36 0x7fcb043f2725 0x7fcb2b938a62 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549576 0x604173 0x5f5506\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mggarrofe\u001b[0m (\u001b[33mguillemgarrofe\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220726_184713-3o11mioy\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcool-cosmos-455\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/guillemgarrofe/controllable-neural-rendering\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/guillemgarrofe/controllable-neural-rendering/runs/3o11mioy\u001b[0m\n","tcmalloc: large alloc 2304000000 bytes == 0x14f5b2000 @  0x7fcb49678b6b 0x7fcb49698379 0x7fcad9c6ed57 0x7fcad9c5cbc3 0x7fcb03b5156f 0x7fcb03b517ba 0x7fcb03b5181f 0x7fcb04064059 0x7fcb048d49c0 0x7fcb0462043e 0x7fcb048adc7e 0x7fcb046602c2 0x7fcb0405e501 0x7fcb04a25e2b 0x7fcb043ab1cf 0x7fcb048afdfc 0x7fcb043ab1cf 0x7fcb0592155b 0x7fcb059219be 0x7fcb04423164 0x7fcb0405345b 0x7fcb04b23350 0x7fcb04553bdf 0x7fcb2b7fe85f 0x7fcb2b7fe8fc 0x7fcb2b7ffdc8 0x59b1b0 0x515655 0x549576 0x593fce 0x548ae9\n","Running kmeans on cuda: 8it [01:51, 13.93s/it, center_shift=0.081971, num_clusters=599, tol=0.100000]\n","Computing linear mappings: 100% 599/599 [01:11<00:00,  8.40linear mapping/s]\n","  0% 0/200000 [00:00<?, ?iteration/s]WARNING - 2022-07-26 18:50:34,877 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:34,896 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:34,919 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 18:50:39,945 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:39,966 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:39,986 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 18:50:44,557 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:44,578 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:44,599 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 18:50:49,276 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:49,295 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:50:49,314 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 200/200000 [05:36<85:20:55,  1.54s/iteration]WARNING - 2022-07-26 18:56:03,718 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:03,737 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:03,757 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 18:56:08,328 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:08,347 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:08,364 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 18:56:12,831 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:12,854 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:12,877 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 18:56:17,462 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:17,482 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 18:56:17,499 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 400/200000 [11:06<85:15:52,  1.54s/iteration]WARNING - 2022-07-26 19:01:33,450 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:33,470 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:33,493 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:01:38,098 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:38,117 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:38,137 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:01:42,603 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:42,623 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:42,643 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:01:47,215 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:47,233 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:01:47,252 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 600/200000 [16:36<85:28:33,  1.54s/iteration]WARNING - 2022-07-26 19:07:03,705 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:03,723 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:03,741 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:07:08,365 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:08,384 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:08,404 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:07:12,854 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:12,875 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:12,897 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:07:17,464 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:17,483 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:07:17,503 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 800/200000 [22:05<84:38:20,  1.53s/iteration]WARNING - 2022-07-26 19:12:32,513 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:32,531 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:32,550 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:12:37,157 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:37,175 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:37,193 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:12:41,731 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:41,750 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:41,768 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:12:46,389 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:46,410 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:12:46,428 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 1000/200000 [27:34<83:57:11,  1.52s/iteration]WARNING - 2022-07-26 19:18:01,694 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:01,712 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:01,730 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:18:06,366 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:06,384 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:06,402 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:18:10,871 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:10,894 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:10,916 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-26 19:18:16,177 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:16,195 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-26 19:18:16,214 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  1% 1058/200000 [29:24<84:54:58,  1.54s/iteration]"]}]},{"cell_type":"markdown","source":["# Reflectance Linear Mapping"],"metadata":{"id":"oozGNYuQjeyw"}},{"cell_type":"code","source":["! python3 drive/Othercomputers/MacBookPro/Rendering/reflectance_mapping.py -c drive/Othercomputers/MacBookPro/Rendering/configs/reflectancemap_colab.conf"],"metadata":{"id":"d_i9K5kWw7ZE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e4d34c6-bc00-40cd-9885-4c104afb827e","executionInfo":{"status":"ok","timestamp":1658936537564,"user_tz":-60,"elapsed":826079,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}}},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/drive/Othercomputers/MacBookPro/Rendering', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '../', 'drive/Othercomputers/MacBookPro/', '../']\n","Using cuda\n","dataset to:  cpu\n","['train', 'val']\n","tcmalloc: large alloc 1612800000 bytes == 0x96a8000 @  0x7f6bdc3c6001 0x7f6b6bcb41af 0x7f6b6bd0ac23 0x7f6b6bd0ba87 0x7f6b6bdad823 0x5936cc 0x548c51 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f6bdbfc1c87 0x5b621a\n","Loading train - 100 poses, images (800x800) and lights...\n","\tChanged 1150 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (0, 0, 0) to (99, 2, 3)\n","Loading val - 5 poses, images (800x800) and lights...\n","\tChanged 59 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (100, 0, 0) to (104, 2, 3)\n","Focal length: 785.0441767523804\n","Generating rays: 100% 105/105 [00:19<00:00,  5.52pose/s]\n","tcmalloc: large alloc 3225600000 bytes == 0x129cea000 @  0x7f6bdc3a6b6b 0x7f6bdc3c6379 0x7f6b6c99cd57 0x7f6b6c98abc3 0x7f6b9688039f 0x7f6b96880d10 0x7f6b96880d64 0x7f6b96880eaf 0x7f6b9760653b 0x7f6b97669a52 0x7f6b96dab047 0x7f6b9760f5ae 0x7f6b9760f633 0x7f6b97120725 0x7f6b96dbd741 0x7f6b97753983 0x7f6b9722790c 0x7f6b9873fb1d 0x7f6b98740026 0x7f6b972791d2 0x7f6bbe644343 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96\n","Creating datasets...\n","tcmalloc: large alloc 3072000000 bytes == 0x698be000 @  0x7f6bdc3a6b6b 0x7f6bdc3c6379 0x7f6b6c99cd57 0x7f6b6c98abc3 0x7f6b9688039f 0x7f6b96880d10 0x7f6b96880d64 0x7f6b96d91fff 0x7f6b9760289b 0x7f6b9734e223 0x7f6b975dd9bf 0x7f6b9738bbf7 0x7f6b968c432c 0x7f6b968c5dcf 0x7f6b968c7783 0x7f6b96d5a0a6 0x7f6b96d66cd9 0x7f6b97602d10 0x7f6b972142bc 0x7f6b9871487d 0x7f6b98714f63 0x7f6b972640fb 0x7f6bbe7cb8e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","tcmalloc: large alloc 1536000000 bytes == 0x7f6a8573c000 @  0x7f6bdc3a6b6b 0x7f6bdc3c6379 0x7f6b6c99cd57 0x7f6b6c98abc3 0x7f6b9688039f 0x7f6b96880d10 0x7f6b96880d64 0x7f6b96d91fff 0x7f6b9760289b 0x7f6b9734e223 0x7f6b975dd9bf 0x7f6b9738bbf7 0x7f6b968c432c 0x7f6b968c5dcf 0x7f6b968c7783 0x7f6b96d5a0a6 0x7f6b96d66cd9 0x7f6b97602d10 0x7f6b972142bc 0x7f6b9871487d 0x7f6b98714f63 0x7f6b972640fb 0x7f6bbe7cb8e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","\tComputing view dirs for train...\n","tcmalloc: large alloc 4608000000 bytes == 0x7f68da34c000 @  0x7f6bdc3a6b6b 0x7f6bdc3c6379 0x7f6b6c99cd57 0x7f6b6c98abc3 0x7f6b9688039f 0x7f6b96880d10 0x7f6b96880d64 0x7f6b96880eaf 0x7f6b9760653b 0x7f6b97669a52 0x7f6b96dab047 0x7f6b9760f5ae 0x7f6b9760f633 0x7f6b970e466c 0x7f6b98658380 0x7f6b98658b36 0x7f6b97120725 0x7f6bbe666a62 0x593835 0x548c51 0x5127f1 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576\n","\tCreating train dataset with rays (torch.Size([64000000, 9])) and images (torch.Size([64000000, 3])) - shuffle True\n","\tComputing view dirs for val...\n","\tCreating val dataset with rays (torch.Size([3200000, 9])) and images (torch.Size([3200000, 3])) - shuffle True\n","Datasets created successfully\n","\n","Reading PLY file: drive/Othercomputers/MacBookPro/hotdog/hot-dogs2.ply[========================================] 100%\n","tcmalloc: large alloc 4608000000 bytes == 0x9696000 @  0x7f6bdc3a6b6b 0x7f6bdc3c6379 0x7f6b6c99cd57 0x7f6b6c98abc3 0x7f6b9688039f 0x7f6b96880d10 0x7f6b96880d64 0x7f6b96880eaf 0x7f6b9760653b 0x7f6b97669a52 0x7f6b96dab047 0x7f6b9760f5ae 0x7f6b9760f633 0x7f6b970e466c 0x7f6b98658380 0x7f6b98658b36 0x7f6b97120725 0x7f6bbe666a62 0x593835 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x604173\n","Generating ray lights: 100% 100/100 [00:17<00:00,  5.71pose/s]\n","tcmalloc: large alloc 3072000000 bytes == 0x7f6821196000 @  0x7f6bdc3a6b6b 0x7f6bdc3c6379 0x7f6b6c99cd57 0x7f6b6c98abc3 0x7f6b9688039f 0x7f6b96880d10 0x7f6b96880d64 0x7f6b96880eaf 0x7f6b9760653b 0x7f6b97669a52 0x7f6b96dab047 0x7f6b9760f5ae 0x7f6b9760f633 0x7f6b97120725 0x7f6b96dbd741 0x7f6b97753983 0x7f6b9722790c 0x7f6b9873fb1d 0x7f6b98740026 0x7f6b972791d2 0x7f6bbe644343 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x604173\n","Generating ray lights: 100% 5/5 [00:00<00:00,  5.40pose/s]\n","Running kmeans on cuda: 23it [05:13, 13.64s/it, center_shift=0.009523, num_clusters=599, tol=0.010000]\n","Computing linear mappings: 100% 599/600 [02:50<00:00,  3.58linear mapping/s]\n","Filtering 34837302 points:   0% 0/35 [00:00<?, ?batch/s]\u001b[A\n","Filtering 34837302 points:   3% 1/35 [00:01<01:05,  1.93s/batch]\u001b[A\n","Filtering 34837302 points:   6% 2/35 [00:03<01:01,  1.86s/batch]\u001b[A\n","Filtering 34837302 points:   9% 3/35 [00:05<00:58,  1.83s/batch]\u001b[A\n","Filtering 34837302 points:  11% 4/35 [00:07<00:56,  1.81s/batch]\u001b[A\n","Filtering 34837302 points:  14% 5/35 [00:09<00:53,  1.79s/batch]\u001b[A\n","Filtering 34837302 points:  17% 6/35 [00:10<00:51,  1.77s/batch]\u001b[A\n","Filtering 34837302 points:  20% 7/35 [00:12<00:48,  1.75s/batch]\u001b[A\n","Filtering 34837302 points:  23% 8/35 [00:14<00:46,  1.73s/batch]\u001b[A\n","Filtering 34837302 points:  26% 9/35 [00:15<00:44,  1.73s/batch]\u001b[A\n","Filtering 34837302 points:  29% 10/35 [00:17<00:43,  1.72s/batch]\u001b[A\n","Filtering 34837302 points:  31% 11/35 [00:19<00:41,  1.73s/batch]\u001b[A\n","Filtering 34837302 points:  34% 12/35 [00:21<00:39,  1.72s/batch]\u001b[A\n","Filtering 34837302 points:  37% 13/35 [00:22<00:37,  1.71s/batch]\u001b[A\n","Filtering 34837302 points:  40% 14/35 [00:24<00:35,  1.70s/batch]\u001b[A\n","Filtering 34837302 points:  43% 15/35 [00:26<00:34,  1.72s/batch]\u001b[A\n","Filtering 34837302 points:  46% 16/35 [00:27<00:32,  1.73s/batch]\u001b[A\n","Filtering 34837302 points:  49% 17/35 [00:29<00:31,  1.73s/batch]\u001b[A\n","Filtering 34837302 points:  51% 18/35 [00:31<00:29,  1.71s/batch]\u001b[A\n","Filtering 34837302 points:  54% 19/35 [00:33<00:27,  1.71s/batch]\u001b[A\n","Filtering 34837302 points:  57% 20/35 [00:34<00:25,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  60% 21/35 [00:36<00:23,  1.70s/batch]\u001b[A\n","Filtering 34837302 points:  63% 22/35 [00:38<00:22,  1.70s/batch]\u001b[A\n","Filtering 34837302 points:  66% 23/35 [00:39<00:20,  1.70s/batch]\u001b[A\n","Filtering 34837302 points:  69% 24/35 [00:41<00:18,  1.70s/batch]\u001b[A\n","Filtering 34837302 points:  71% 25/35 [00:43<00:17,  1.70s/batch]\u001b[A\n","Filtering 34837302 points:  74% 26/35 [00:44<00:15,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  77% 27/35 [00:46<00:13,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  80% 28/35 [00:48<00:11,  1.68s/batch]\u001b[A\n","Filtering 34837302 points:  83% 29/35 [00:49<00:10,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  86% 30/35 [00:51<00:08,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  89% 31/35 [00:53<00:06,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  91% 32/35 [00:54<00:05,  1.69s/batch]\u001b[A\n","Filtering 34837302 points:  94% 33/35 [00:56<00:03,  1.68s/batch]\u001b[A\n","Filtering 34837302 points:  97% 34/35 [00:58<00:01,  1.68s/batch]\u001b[A\n","Filtering 34837302 points: 100% 35/35 [00:59<00:00,  1.60s/batch]\u001b[A\n","                                                                 \u001b[AFiltered to 316\n","Computing linear mappings: 100% 600/600 [03:51<00:00,  2.59linear mapping/s]\n","evaluating...\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:39:16,702 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:39:16,720 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:39:16,738 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:39:36,759 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:39:36,777 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:39:36,796 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:39:55,845 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:39:55,863 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:39:55,881 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:40:15,813 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:40:15,831 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:40:15,849 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:40:35,319 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:40:35,337 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:40:35,356 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:40:54,782 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:40:54,801 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:40:54,819 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:41:14,616 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:41:14,633 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:41:14,649 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:41:34,392 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:41:34,410 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:41:34,428 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:41:54,047 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:41:54,066 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:41:54,085 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","<Figure size 640x480 with 1 Axes>\n","WARNING - 2022-07-27 15:42:13,564 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:42:13,583 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 15:42:13,601 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","{'loss_tr': tensor(0.0034, device='cuda:0'), 'psnr_tr': tensor([24.6834], device='cuda:0'), 'loss_val': tensor(0.0043, device='cuda:0'), 'psnr_val': tensor([23.6182], device='cuda:0')}\n"]}]},{"cell_type":"markdown","source":["# Reflectance Mapping Network"],"metadata":{"id":"vH5hJcZwjUiV"}},{"cell_type":"code","source":["! python3 drive/Othercomputers/MacBookPro/Rendering/reflectance_mapping_network.py -c drive/Othercomputers/MacBookPro/Rendering/configs/reflectancemap_net_colab.conf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06tpJrprjXhH","executionInfo":{"status":"ok","timestamp":1658965959147,"user_tz":-60,"elapsed":3940285,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}},"outputId":"648020d1-3e7d-41be-9e39-8f59c95afc81"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["drive/Othercomputers/MacBookPro/utils/utils.py:20: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert(old_arr.shape == new_arr.shape, \"The 2 arrays have different shape, cannot find the differences.\")\n","['/content/drive/Othercomputers/MacBookPro/Rendering', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '../', 'drive/Othercomputers/MacBookPro/', '../']\n","Using cuda\n","dataset to:  cpu\n","['train', 'val']\n","tcmalloc: large alloc 1612800000 bytes == 0x8064000 @  0x7f962f9a3001 0x7f95bf2911af 0x7f95bf2e7c23 0x7f95bf2e8a87 0x7f95bf38a823 0x5936cc 0x548c51 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f962f59ec87 0x5b621a\n","Loading train - 100 poses, images (800x800) and lights...\n","\tChanged 1150 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (0, 0, 0) to (99, 2, 3)\n","Loading val - 5 poses, images (800x800) and lights...\n","\tChanged 59 items out of 1260 in array of shape (105, 3, 4)\n","\t\tFrom (100, 0, 0) to (104, 2, 3)\n","Focal length: 785.0441767523804\n","Generating rays: 100% 105/105 [00:18<00:00,  5.63pose/s]\n","tcmalloc: large alloc 3225600000 bytes == 0x1286a6000 @  0x7f962f983b6b 0x7f962f9a3379 0x7f95bff79d57 0x7f95bff67bc3 0x7f95e9e5d39f 0x7f95e9e5dd10 0x7f95e9e5dd64 0x7f95e9e5deaf 0x7f95eabe353b 0x7f95eac46a52 0x7f95ea388047 0x7f95eabec5ae 0x7f95eabec633 0x7f95ea6fd725 0x7f95ea39a741 0x7f95ead30983 0x7f95ea80490c 0x7f95ebd1cb1d 0x7f95ebd1d026 0x7f95ea8561d2 0x7f9611c21343 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96\n","Creating datasets...\n","tcmalloc: large alloc 3072000000 bytes == 0x6827a000 @  0x7f962f983b6b 0x7f962f9a3379 0x7f95bff79d57 0x7f95bff67bc3 0x7f95e9e5d39f 0x7f95e9e5dd10 0x7f95e9e5dd64 0x7f95ea36efff 0x7f95eabdf89b 0x7f95ea92b223 0x7f95eabba9bf 0x7f95ea968bf7 0x7f95e9ea132c 0x7f95e9ea2dcf 0x7f95e9ea4783 0x7f95ea3370a6 0x7f95ea343cd9 0x7f95eabdfd10 0x7f95ea7f12bc 0x7f95ebcf187d 0x7f95ebcf1f63 0x7f95ea8410fb 0x7f9611da88e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","tcmalloc: large alloc 1536000000 bytes == 0x7f94d8d16000 @  0x7f962f983b6b 0x7f962f9a3379 0x7f95bff79d57 0x7f95bff67bc3 0x7f95e9e5d39f 0x7f95e9e5dd10 0x7f95e9e5dd64 0x7f95ea36efff 0x7f95eabdf89b 0x7f95ea92b223 0x7f95eabba9bf 0x7f95ea968bf7 0x7f95e9ea132c 0x7f95e9ea2dcf 0x7f95e9ea4783 0x7f95ea3370a6 0x7f95ea343cd9 0x7f95eabdfd10 0x7f95ea7f12bc 0x7f95ebcf187d 0x7f95ebcf1f63 0x7f95ea8410fb 0x7f9611da88e2 0x4d3969 0x512147 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86\n","\tComputing view dirs for train...\n","tcmalloc: large alloc 4608000000 bytes == 0x7f932d926000 @  0x7f962f983b6b 0x7f962f9a3379 0x7f95bff79d57 0x7f95bff67bc3 0x7f95e9e5d39f 0x7f95e9e5dd10 0x7f95e9e5dd64 0x7f95e9e5deaf 0x7f95eabe353b 0x7f95eac46a52 0x7f95ea388047 0x7f95eabec5ae 0x7f95eabec633 0x7f95ea6c166c 0x7f95ebc35380 0x7f95ebc35b36 0x7f95ea6fd725 0x7f9611c43a62 0x593835 0x548c51 0x5127f1 0x549e0e 0x593fce 0x511e2c 0x549576 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576\n","\tCreating train dataset with rays (torch.Size([64000000, 9])) and images (torch.Size([64000000, 3])) - shuffle True\n","\tComputing view dirs for val...\n","\tCreating val dataset with rays (torch.Size([3200000, 9])) and images (torch.Size([3200000, 3])) - shuffle True\n","Datasets created successfully\n","\n","Reading PLY file: drive/Othercomputers/MacBookPro/hotdog/hot-dogs2.ply[========================================] 100%\n","Generating ray lights: 100% 100/100 [00:17<00:00,  5.70pose/s]\n","tcmalloc: large alloc 3072000000 bytes == 0x7f9274770000 @  0x7f962f983b6b 0x7f962f9a3379 0x7f95bff79d57 0x7f95bff67bc3 0x7f95e9e5d39f 0x7f95e9e5dd10 0x7f95e9e5dd64 0x7f95e9e5deaf 0x7f95eabe353b 0x7f95eac46a52 0x7f95ea388047 0x7f95eabec5ae 0x7f95eabec633 0x7f95ea6fd725 0x7f95ea39a741 0x7f95ead30983 0x7f95ea80490c 0x7f95ebd1cb1d 0x7f95ebd1d026 0x7f95ea8561d2 0x7f9611c21343 0x593784 0x548c51 0x51566f 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x604173\n","Generating ray lights: 100% 5/5 [00:00<00:00,  5.87pose/s]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mggarrofe\u001b[0m (\u001b[33mguillemgarrofe\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220727_224816-shcd0nuv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-smoke-476\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/guillemgarrofe/controllable-neural-rendering\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/guillemgarrofe/controllable-neural-rendering/runs/shcd0nuv\u001b[0m\n","Running kmeans on cuda: 27it [05:41, 12.66s/it, center_shift=0.009410, num_clusters=599, tol=0.010000]\n","Filtered 34837302 points to 316\n","Computing linear mappings: 100% 600/600 [03:38<00:00,  2.74linear mapping/s]\n","  0% 0/100000 [00:00<?, ?iteration/s]WARNING - 2022-07-27 22:57:53,453 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:57:53,472 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:57:53,491 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 22:58:06,873 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:58:06,891 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:58:06,909 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 22:58:09,495 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:58:09,513 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:58:09,531 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 22:58:12,849 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:58:12,866 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 22:58:12,884 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 15/100000 [00:47<30:25:17,  1.10s/iteration]\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n","  0% 200/100000 [04:17<35:09:10,  1.27s/iteration]WARNING - 2022-07-27 23:02:02,060 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:02,080 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:02,098 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:02:04,801 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:04,818 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:04,836 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:02:08,160 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:08,179 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:08,199 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:02:10,933 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:10,951 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:02:10,970 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  0% 400/100000 [08:16<33:15:25,  1.20s/iteration]WARNING - 2022-07-27 23:06:00,542 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:00,563 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:00,584 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:06:03,244 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:03,262 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:03,280 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:06:06,551 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:06,569 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:06,587 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:06:09,295 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:09,314 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:06:09,333 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  1% 600/100000 [12:14<33:10:56,  1.20s/iteration]WARNING - 2022-07-27 23:09:59,286 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:09:59,305 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:09:59,323 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:10:02,041 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:10:02,059 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:10:02,078 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:10:05,368 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:10:05,386 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:10:05,405 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:10:08,100 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:10:08,119 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:10:08,137 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  1% 800/100000 [16:13<32:54:08,  1.19s/iteration]WARNING - 2022-07-27 23:13:57,970 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:13:57,991 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:13:58,010 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:14:00,721 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:14:00,740 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:14:00,759 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:14:04,063 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:14:04,083 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:14:04,103 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:14:06,783 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:14:06,802 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:14:06,820 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  1% 1000/100000 [20:12<32:53:42,  1.20s/iteration]WARNING - 2022-07-27 23:17:56,774 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:17:56,792 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:17:56,811 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:17:59,529 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:17:59,547 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:17:59,565 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:18:02,892 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:18:02,911 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:18:02,931 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:18:05,674 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:18:05,691 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:18:05,709 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  1% 1200/100000 [24:09<32:40:01,  1.19s/iteration]WARNING - 2022-07-27 23:21:54,254 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:21:54,272 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:21:54,290 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:21:56,963 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:21:56,981 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:21:57,000 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:22:00,286 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:22:00,304 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:22:00,323 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:22:02,971 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:22:02,991 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:22:03,010 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  1% 1400/100000 [28:07<32:36:26,  1.19s/iteration]WARNING - 2022-07-27 23:25:51,667 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:25:51,686 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:25:51,705 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:25:54,382 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:25:54,401 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:25:54,418 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:25:57,683 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:25:57,701 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:25:57,721 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:26:00,419 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:26:00,437 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:26:00,455 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  2% 1600/100000 [32:04<32:38:45,  1.19s/iteration]WARNING - 2022-07-27 23:29:49,424 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:49,443 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:49,461 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:29:52,141 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:52,158 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:52,177 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:29:55,479 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:55,497 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:55,515 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:29:58,076 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:58,093 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:29:58,111 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  2% 1800/100000 [36:02<32:32:28,  1.19s/iteration]WARNING - 2022-07-27 23:33:47,266 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:47,284 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:47,303 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:33:49,967 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:49,986 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:50,004 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:33:53,298 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:53,317 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:53,336 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:33:56,045 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:56,062 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:33:56,080 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  2% 2000/100000 [40:00<32:21:31,  1.19s/iteration]WARNING - 2022-07-27 23:37:45,278 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:45,297 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:45,316 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:37:47,979 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:47,997 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:48,018 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:37:51,309 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:51,330 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:51,348 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:37:53,938 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:53,956 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:37:53,974 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  2% 2200/100000 [43:58<32:33:57,  1.20s/iteration]WARNING - 2022-07-27 23:41:43,359 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:43,378 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:43,397 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:41:46,068 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:46,087 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:46,105 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:41:49,368 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:49,390 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:49,408 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:41:52,110 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:52,128 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:41:52,145 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  2% 2400/100000 [47:57<32:27:01,  1.20s/iteration]WARNING - 2022-07-27 23:45:41,519 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:41,538 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:41,556 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:45:44,237 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:44,254 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:44,274 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:45:47,540 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:47,559 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:47,577 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:45:50,280 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:50,299 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:45:50,317 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  3% 2600/100000 [51:54<32:24:34,  1.20s/iteration]WARNING - 2022-07-27 23:49:39,447 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:39,465 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:39,484 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:49:42,143 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:42,161 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:42,178 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:49:45,431 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:45,449 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:45,467 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","WARNING - 2022-07-27 23:49:48,079 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:48,097 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING - 2022-07-27 23:49:48,115 - image - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","<Figure size 2500x1000 with 4 Axes>\n","  3% 2739/100000 [54:43<33:10:01,  1.23s/iteration]Traceback (most recent call last):\n","  File \"drive/Othercomputers/MacBookPro/Rendering/reflectance_mapping_network.py\", line 213, in <module>\n","    batch_x_NdotL_NdotH_val, target_rgb_val = dataset.next_batch(\"val\", device=device)\n","  File \"drive/Othercomputers/MacBookPro/utils/data.py\", line 456, in next_batch\n","    return subdataset.next_batch(device)\n","  File \"drive/Othercomputers/MacBookPro/utils/data.py\", line 258, in next_batch\n","    batch_rays, target_rgb = next(self.iterator)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 652, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 692, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 188, in __getitem__\n","    return tuple(tensor[index] for tensor in self.tensors)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 188, in <genexpr>\n","    return tuple(tensor[index] for tensor in self.tensors)\n","KeyboardInterrupt\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  tr_loss ▃▅▅▄▁▅▅▆▄▂▄▅▆▆▄▅▂▂▂▄█▅▄▃▅▄▄▄▅▅▄▃▃▅▅▇▅▅▅▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:  tr_psnr ▅▄▄▅█▄▄▃▅▆▄▃▃▃▅▄▇▇▆▅▁▄▅▅▄▄▅▅▄▃▅▆▅▄▃▂▄▄▄▄\n","\u001b[34m\u001b[1mwandb\u001b[0m: val_loss ▂▄▂▄▃▂▄▆▅▅▃▃▃▄▄▃▅▅▄▅▁▄▃▃▅█▃▁▃▃▂▃▄▃▃▅▄▂▂▃\n","\u001b[34m\u001b[1mwandb\u001b[0m: val_psnr ▇▄▆▅▆▇▅▃▄▄▆▆▆▅▄▆▄▄▅▃█▅▆▆▃▁▆█▅▅▇▆▅▆▆▄▅▇▇▆\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  tr_loss 0.00265\n","\u001b[34m\u001b[1mwandb\u001b[0m:  tr_psnr 25.77537\n","\u001b[34m\u001b[1mwandb\u001b[0m: val_loss 0.00466\n","\u001b[34m\u001b[1mwandb\u001b[0m: val_psnr 23.31876\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrich-smoke-476\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/guillemgarrofe/controllable-neural-rendering/runs/shcd0nuv\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 56 media file(s), 0 artifact file(s) and 1 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220727_224816-shcd0nuv/logs\u001b[0m\n","  3% 2739/100000 [54:53<32:29:14,  1.20s/iteration]\n"]}]},{"cell_type":"code","source":["import torch\n","t1 = torch.tensor([[1, 2, 3], [4, 5, 6], [1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","\n","unique, inverse = torch.unique(t1, sorted=True, return_inverse=True, dim=0)\n","perm = torch.arange(inverse.size(0), dtype=inverse.dtype, device=inverse.device)\n","inverse, perm = inverse.flip([0]), perm.flip([0])\n","print(unique)\n","print(inverse)\n","perm = inverse.new_empty(unique.size(0)).scatter_(0, inverse, perm)\n","print(perm)"],"metadata":{"id":"bEKtpUsLkEDj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658579073545,"user_tz":-60,"elapsed":206,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}},"outputId":"12905460-5c0d-4e2a-e60d-73e4c572ab53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","tensor([2, 1, 0, 1, 0])\n","tensor([0, 1, 4])\n"]}]},{"cell_type":"code","source":["x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n","index = torch.tensor([0, 2])\n","x.index_fill_(0, index, -1)\n","\n","cluster_ids = []"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PN0hRKzC-9je","executionInfo":{"status":"ok","timestamp":1658932255976,"user_tz":-60,"elapsed":7,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}},"outputId":"49e9c7f2-b8cd-4d30-a966-5f6e40c6cf38"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.5066, -0.0317,  0.7404, -0.8176],\n","        [ 1.2103, -1.2459, -0.9263,  1.2217],\n","        [-0.0228, -1.3056,  0.7262,  0.2709],\n","        [-0.6637, -2.1896, -0.3487, -1.2596]])\n","tensor([[False, False,  True,  True],\n","        [False, False,  True,  True],\n","        [False, False,  True,  True],\n","        [False, False,  True,  True]])\n","tensor([2, 3, 2, 2])\n"]}]},{"cell_type":"code","source":["X = torch.tensor([[1., 2., 3.], [4., 5., 6.], [1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","cluster_ids = torch.arange(0, end=5)\n","cluster_ids = cluster_ids[torch.randperm(cluster_ids.shape[0])]\n","\n","values = torch.rand((5, 10))\n","print(values)\n","col_indices = torch.stack([cluster_ids, cluster_ids+1, cluster_ids+2], dim=0)\n","print(col_indices)\n","row_indices = torch.arange(5)\n","print(values[row_indices, col_indices].T)\n","print(values[row_indices, col_indices].T.shape)\n"],"metadata":{"id":"bX9HgIyMo0Ye","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658937704446,"user_tz":-60,"elapsed":401,"user":{"displayName":"Guillem garrofé","userId":"02696913160405475090"}},"outputId":"426065c6-d827-4cd3-8927-76cd7649537f"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[9.2120e-01, 6.5819e-01, 4.7914e-01, 1.4890e-01, 5.2660e-01, 6.3940e-01,\n","         9.8772e-01, 5.9303e-01, 7.0703e-01, 8.4739e-01],\n","        [8.5110e-01, 4.0239e-04, 2.8202e-01, 9.1530e-01, 1.8869e-01, 4.2283e-01,\n","         2.7864e-01, 1.2488e-01, 4.7079e-01, 2.5965e-01],\n","        [6.6420e-01, 7.4319e-01, 7.1035e-01, 9.8808e-01, 5.7236e-01, 3.9414e-01,\n","         9.3400e-05, 8.8030e-01, 5.3952e-01, 1.6256e-01],\n","        [9.9138e-01, 9.0262e-01, 4.6338e-01, 7.3467e-01, 6.1284e-01, 4.9806e-01,\n","         5.6239e-01, 3.8199e-01, 4.3856e-01, 4.6844e-01],\n","        [9.2781e-01, 5.1247e-01, 4.5681e-01, 5.4670e-01, 2.5513e-01, 3.3994e-01,\n","         3.1610e-01, 4.8427e-01, 7.8315e-01, 8.5255e-02]])\n","tensor([[2, 0, 1, 4, 3],\n","        [3, 1, 2, 5, 4],\n","        [4, 2, 3, 6, 5]])\n","tensor([[4.7914e-01, 1.4890e-01, 5.2660e-01],\n","        [8.5110e-01, 4.0239e-04, 2.8202e-01],\n","        [7.4319e-01, 7.1035e-01, 9.8808e-01],\n","        [6.1284e-01, 4.9806e-01, 5.6239e-01],\n","        [5.4670e-01, 2.5513e-01, 3.3994e-01]])\n","torch.Size([5, 3])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"w661fgkcleJB"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"run_nerf.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}